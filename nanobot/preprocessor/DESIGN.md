# 消息预处理器设计文档

## 概述

本文档阐述消息预处理器的设计思路、理论依据和实现逻辑。

## 核心设计原则

### 1. 分离关注点：LLM 做分类，代码做计算

**问题**：让 LLM 直接估算数值（如"偏见程度 70%"）结果不稳定、不可审计。

**解决方案**：
- LLM 负责识别和分类（输出列表）
- 代码负责量化和计算（输出数值）

```
LLM 输出（分类）          代码计算（量化）
─────────────────        ─────────────────
["情绪词1", "情绪词2"] →  情绪词数 / 总句数 → sigmoid 映射 → 0.85
```

**优势**：
- 可审计：可以追溯每个数值的来源
- 可复现：同样的列表输入产生同样的数值输出
- 更可靠：避免了 LLM 数值估计的不稳定性

### 2. 原文参照系

**问题**：如何确保计算的客观性？

**解决方案**：使用原文的客观属性作为恒定参照系（类似物理学中的光速）。

```
原文客观属性：
├── 总字数 = len(message) - 空格数
├── 总句数 = 按标点分割后的句子数
└── 这些属性是确定的、可验证的
```

**所有比例计算都以此参照系为分母**：

```python
# 正确：以原文属性为参照
主观比例 = 主观部分字数 / 原文总字数

# 错误：以 LLM 输出互为参照
主观比例 = 主观部分字数 / (主观部分字数 + 客观部分字数)
```

### 3. 适用于中英文

**问题**：中文分词不明确，"词数"难以准确定义。

**解决方案**：统一使用"字数"（去除空格后的字符数）作为计量单位。

```python
total_chars = len(message.replace(" ", "").replace("\n", ""))
```

这对英文同样适用，因为英文单词长度变化大，用字符数反而更公平。

---

## 防幻觉机制

### 问题：LLM 提取内容膨胀

LLM 有时会"过度解读"原文，提取出原文中不存在的内容：

```
原文："我不喜欢这个。"

LLM 提取（错误）:
emotional_words: ["厌恶", "憎恨", "反感"]  # 这些词原文中根本没有！

后果：分子（提取词字数）膨胀，甚至超过分母（原文总字数）
```

### 解决方案：双重保障

#### 1. Prompt 约束

在 Prompt 中明确要求精确引用：

```
【重要规则】
所有提取内容必须是原文的**精确引用**（Quote）：
- 直接复制原文中的词句，不要改写、不要推断、不要扩展
- 如果原文是"不喜欢"，不要提取为"厌恶"或"憎恨"
- 如果原文没有明确说出某个词，就不要提取该词
```

#### 2. 代码校验

即使有 Prompt 约束，仍需代码校验作为兜底：

```python
def validate_extraction(item: str, original_message: str, min_overlap: float = 0.5) -> bool:
    """
    验证提取内容是否真实存在于原文中

    检查字符重叠率，过滤掉"幻觉"提取项
    """
    item_chars = set(item)
    original_chars = set(original_message)
    overlap = len(item_chars & original_chars) / len(item_chars)
    return overlap >= min_overlap  # 至少 50% 字符需要在原文中出现
```

#### 需要验证 vs 不需要验证的字段

| 需要验证（精确引用） | 不需要验证（分类/概括） |
|---------------------|------------------------|
| subjective_parts | bias_types（分类名称） |
| objective_parts | missing_context（允许概括） |
| emotional_words | |
| clear_topics | |
| vague_expressions | |
| ... | |

---

## JSON Schema 结构化输出

### 问题：LLM 输出格式不稳定

仅靠 Prompt 约束 JSON 格式不够可靠：
- LLM 可能输出非 JSON 内容
- 字段名可能拼写错误
- 可能遗漏必需字段

### 解决方案：JSON Schema Structured Output

OpenAI 兼容 API 支持 `response_format` 参数强制输出格式：

```python
response = await client.chat.completions.create(
    model=model,
    messages=[...],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "analysis_result",
            "strict": True,
            "schema": {
                "type": "object",
                "properties": {
                    "subjective_parts": {"type": "array", "items": {"type": "string"}},
                    "objective_parts": {"type": "array", "items": {"type": "string"}},
                    # ... 其他字段
                },
                "required": ["subjective_parts", "objective_parts", ...],
                "additionalProperties": False
            }
        }
    }
)
```

### 优势

1. **类型安全**：强制输出符合 Schema 的 JSON
2. **字段完整**：`required` 确保所有必需字段都存在
3. **无额外内容**：`additionalProperties: False` 防止多余字段
4. **无需解析**：输出直接是有效的 JSON 对象

### 当前实现

定义了两个 Schema：
- `ANALYSIS_SCHEMA`：主分析输出格式
- `REVIEW_SCHEMA`：复核补充输出格式

---

## 分析流程

```
用户消息
    │
    ▼
┌─────────────────────────────────────┐
│  第 1 轮：One-shot 分析              │
│  ─────────────────────              │
│  LLM 识别并输出各类列表：            │
│  • subjective_parts (主观陈述)      │
│  • objective_parts (客观陈述)       │
│  • bias_types (偏见类型)            │
│  • emotional_words (情绪词)         │
│  • clear_topics (明确主题)          │
│  • ...                              │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│  指标计算（代码）                    │
│  ─────────────────                  │
│  基于列表字数 / 原文参照系           │
│  • subjective_ratio                 │
│  • confidence_score                 │
│  • bias_score (sigmoid 映射)        │
│  • topic_clarity, ...               │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│  第 2 轮：复核（可选）               │
│  ────────────                       │
│  LLM 检查遗漏项                      │
│  计算补充比例 → analysis_confidence  │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│  熵值计算（动态权重）                │
│  ───────────────────                │
│  H = sigmoid((1-C) + C×η + u,       │
│      k=4.0, center=0.75)            │
└─────────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────────┐
│  输出                               │
│  ────                               │
│  原文消息 + 分析数据（JSON）         │
└─────────────────────────────────────┘
```

**总计 2 次 LLM 调用**（分析 + 复核，复核可跳过）

---

## 熵值公式详解

### 公式结构

```
H_info = (1 - C) + C × η + uncertainty
```

### 公式解读

**H_info（信息熵）**：衡量消息处理的不确定性/复杂度
- 取值范围：[0, 1]（sigmoid 归一化后）
- 0: 非常容易处理的消息
- 1: 非常难以处理的消息

**Sigmoid 归一化处理**：
由于公式特性，原始熵值 H_raw 实际分布约为 [0.5, 0.95]，使用 sigmoid 进行平滑映射：
```
H = sigmoid(H_raw, k=4.0, center=0.75)
```
其中 sigmoid 函数为：`σ(x) = 1 / (1 + e^(-k*(x-center)))`

**映射效果**：
| H_raw | H (归一化后) | 含义 |
|-------|-------------|------|
| 0.60  | 0.28        | 容易处理 |
| 0.75  | 0.50        | 中等难度 |
| 0.85  | 0.73        | 较难处理 |
| 0.95  | 0.92        | 很难处理 |

**为什么用 sigmoid 而非线性映射**：
- 线性映射对分布假设敏感，实际值可能偏离预期范围
- Sigmoid 自然地将值平滑映射到 (0, 1)，无截断问题
- 通过调整 center 和 k 参数可以灵活控制分布

**C（覆盖率）**：衡量信息的完整性和清晰度
- 公式：`C = w_topic × θ + w_context × κ + w_requirement × ρ`
- 高覆盖率 → 主题明确、上下文完整、需求清晰
- 低覆盖率 → 信息模糊、缺乏上下文、需求不明

**η（噪声）**：衡量信息的干扰因素
- 公式：`η = 0.3 × δ + 0.4 × μ + 0.3 × ε + bias_noise`
- 高噪声 → 冗余、歧义、情绪干扰、偏见
- 低噪声 → 信息纯净、表达清晰

**uncertainty（不确定性）**：衡量分析本身的可靠性
- 公式：`uncertainty = (1 - analysis_confidence) × 0.1`
- 高不确定性 → 复核发现大量遗漏，分析不可靠
- 低不确定性 → 分析结果可信

### 动态权重机制

**核心理念**：熵值公式的权重不应是固定的，而应根据消息特性动态调整。

#### 主观性影响覆盖率权重

```
基础权重: w_topic = 0.4, w_context = 0.3, w_requirement = 0.3

当主观性高时:
  - w_context 降低：主观消息的上下文参考价值有限
  - w_requirement 升高：更需要理解用户的真实意图

调整公式:
  w_context = 0.3 × (1 - 0.2 × subjective_ratio)
  w_requirement = 0.3 × (1 + 0.2 × subjective_ratio)
```

**示例**：

| 主观性 | w_topic | w_context | w_requirement | 解读 |
|--------|---------|-----------|---------------|------|
| 0%     | 0.40    | 0.30      | 0.30          | 客观消息，权重均衡 |
| 50%    | 0.38    | 0.27      | 0.35          | 中度主观，略向需求倾斜 |
| 100%   | 0.36    | 0.24      | 0.40          | 高度主观，重点关注用户意图 |

#### 偏见作为额外噪声

```
η = 基础噪声 + bias_score × 0.2
```

**理论依据**：偏见本身就是信息噪声，会干扰对消息的理解和处理。

| 偏见评分 | 额外噪声 | 影响 |
|----------|----------|------|
| 0%       | 0.00     | 无影响 |
| 50%      | 0.10     | 中等影响 |
| 100%     | 0.20     | 显著影响 |

#### 分析置信度影响不确定性

```
uncertainty = (1 - analysis_confidence) × 0.1
```

**理论依据**：如果复核发现大量遗漏，说明初次分析不完整，最终熵值应包含这种不确定性。

| 分析置信度 | 不确定性 | 影响 |
|------------|----------|------|
| 100%       | 0.00     | 无额外不确定性 |
| 50%        | 0.05     | 中等不确定性 |
| 0%         | 0.10     | 最大不确定性（上限 0.1）|

---

## 指标计算逻辑

### 1. 主客观比例 (subjective_ratio)

```
主观比例 = 主观部分字数 / 原文总字数
```

- LLM 识别主观陈述列表
- 代码计算列表内容总字数
- 除以原文总字数

### 2. 事实置信度 (confidence_score)

```
事实置信度 = 可验证陈述数 / 总句数
```

- LLM 识别可验证的事实陈述
- 代码计数并除以原文总句数
- 反映消息中可核实的比例

### 3. 偏见评分 (bias_score)

```
偏见原始分 = (偏见类型数 + 情绪词数) / 总句数
偏见评分 = sigmoid(偏见原始分, k=4.0, center=0.5)
```

**使用 sigmoid 的原因**：
- 避免线性截断导致的信息损失
- 保留高分区域的区分度
- 平滑映射到 [0, 1] 范围

```
sigmoid(x) = 1 / (1 + e^(-k*(x-center)))

特点：
- x = center 时，输出 0.5
- k 控制曲线陡峭度
- 输出永远在 (0, 1) 范围内
```

### 4. 分析置信度 (analysis_confidence)

```
补充比例 = 复核补充项数 / 初次分析项数
分析置信度 = 1 - sigmoid(补充比例, k=4.0, center=0.2)
```

**逻辑**：
- 复核补充越多，说明初次分析遗漏越多
- 遗漏越多，分析的可靠性越低
- 使用 sigmoid 确保平滑映射

---

## 信息质量参数

### 覆盖率相关（越高越好）

| 参数 | 计算方式 | 含义 |
|------|----------|------|
| topic_clarity | 明确主题字数 / 总字数 | 主题是否清晰明确 |
| context_completeness | 已提供背景字数 / 总字数 | 上下文是否完整 |
| requirement_clarity | 明确请求字数 / 总字数 | 需求是否清晰可辨 |

### 噪声相关（越低越好）

| 参数 | 计算方式 | 含义 |
|------|----------|------|
| redundancy | 重复信息字数 / 总字数 | 是否有冗余重复 |
| ambiguity | (歧义表述 + 模糊表达)字数 / 总字数 | 是否存在歧义 |
| emotional_interference | sigmoid((强烈情绪词 + 情绪词)字数 / 总字数 × 10) | 情绪干扰程度 |

---

## 设计权衡

### 1. 为什么用 sigmoid 而非线性映射？

**线性映射**：`min(1.0, raw_score)` 会丢失高分区域的区分度
- 0.8 和 1.0 都被截断为 1.0

**Sigmoid**：保留全程区分度
- 0.8 → 0.69, 1.0 → 0.82, 1.5 → 0.92

### 2. 为什么权重调整系数是 0.2？

- 太小（如 0.1）：影响不明显，失去动态调整意义
- 太大（如 0.5）：可能导致权重失衡
- 0.2 是折中选择，产生约 ±10% 的权重变化

### 3. 为什么不确定性上限是 0.1？

- 熵值的主因素是覆盖率和噪声
- 不确定性只是辅助调整
- 0.1 的上限确保不会主导熵值

---

## 使用场景

### 高熵值消息（H > 0.7）

特征：主观性强、偏见明显、上下文缺失、情绪化

处理建议：
- 需要人工审核
- 可能需要澄清用户意图
- 注意情绪因素

### 低熵值消息（H < 0.3）

特征：客观陈述、主题明确、上下文完整、表达清晰

处理建议：
- 可自动处理
- 直接响应即可
- 置信度高

---

## 版本历史

- **v1**：固定权重熵值公式
- **v2**：列表化输出 + 原文参照系
- **v3**：动态权重 + sigmoid 归一化 + 移除报告生成（当前版本）

---

## 输出格式

分析完成后返回包含以下字段的字典：

```python
{
    # 原文
    "original_message": "用户原始消息",

    # 列表数据（LLM 提取）
    "subjective_parts": ["主观陈述1", ...],
    "objective_parts": ["客观陈述1", ...],
    "bias_types": ["确认偏见", ...],
    "emotional_words": ["情绪词1", ...],
    # ... 其他列表字段

    # 计算指标（代码计算）
    "subjective_ratio": 0.57,      # 主观比例
    "confidence_score": 0.50,      # 事实置信度
    "bias_score": 0.98,            # 偏见评分
    "topic_clarity": 0.05,         # 主题明确度
    "context_completeness": 0.05,  # 上下文完整性
    "requirement_clarity": 0.00,   # 需求清晰度
    "redundancy": 0.00,            # 冗余度
    "ambiguity": 0.10,             # 模糊度
    "emotional_interference": 0.50,# 情绪干扰

    # 熵值相关
    "entropy": 0.75,               # 归一化熵值
    "coverage": 0.05,              # 覆盖率 C
    "noise": 0.50,                 # 噪声 η
    "analysis_confidence": 0.45,   # 分析置信度

    # 调试信息
    "_reference": {
        "total_chars": 49,         # 原文总字数
        "total_sentences": 2,      # 原文总句数
    },
    "_weights_info": {
        "w_topic": 0.40,           # 主题权重
        "w_context": 0.27,         # 上下文权重
        "w_requirement": 0.33,     # 需求权重
        "bias_noise": 0.20,        # 偏见噪声
        "uncertainty": 0.06,       # 不确定性
    }
}
```
